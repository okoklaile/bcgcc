# ğŸ”§ Training Issues - Complete Fix Summary

## é—®é¢˜è¯Šæ–­

### ç¬¬ä¸€æ¬¡è®­ç»ƒå¤±è´¥ (Loss = NaN)
```
Epoch 1: loss=nan, avg_loss=nan
```
**åŸå› **: å½’ä¸€åŒ–èŒƒå›´ä¸åŒ¹é… + å­¦ä¹ ç‡è¿‡é«˜ + æƒé‡è¿‡å¤§

### ç¬¬äºŒæ¬¡è®­ç»ƒå¤±è´¥ (Loss = 6.7e13)
```
Epoch 1: loss=67287587487744, avg_loss=6082697570
GPU-Util: 7%
Speed: 49 it/s
```
**åŸå› **: Target æ²¡æœ‰å½’ä¸€åŒ– + æ•°æ®åŠ è½½æ…¢

---

## å®Œæ•´ä¿®å¤æ–¹æ¡ˆ

### âœ… ä¿®å¤1: å½’ä¸€åŒ–èŒƒå›´è°ƒæ•´ (`src/config.py`)

```python
# ä¹‹å‰: å¤ªå°ï¼Œæç«¯å€¼å¯¼è‡´ NaN
'delay': {'min': 0, 'max': 5000}

# ä¹‹å: è¦†ç›–æ­£å¸¸+ä¸¥é‡æ‹¥å¡ï¼Œclip æç«¯å€¼
'delay': {'min': 0, 'max': 10000}
USE_CLIPPING = True
```

### âœ… ä¿®å¤2: æ·»åŠ  Clipping é€»è¾‘ (`src/dataset.py`)

```python
if config.USE_CLIPPING:
    clamped = torch.clamp(features[:, :, i], min_val, max_val)
    normalized[:, :, i] = (clamped - min_val) / range_val
```

### âœ… ä¿®å¤3: é™ä½å­¦ä¹ ç‡ (`src/config.py`)

```python
LEARNING_RATE = 1e-4  # ä» 1e-3 é™ä½ 10 å€
```

### âœ… ä¿®å¤4: å‡å°æ ·æœ¬æƒé‡ (`src/config.py`)

```python
LOSS_WEIGHT_HAS_LOSS = 10.0   # ä» 50.0 é™ä½
LOSS_WEIGHT_HIGH_DELAY = 5.0  # ä» 10.0 é™ä½
```

### âœ… ä¿®å¤5: å‡å°‘é‡é‡‡æ · (`src/config.py`)

```python
OVERSAMPLE_MULTIPLIERS = [10, 5, 5, 5]  # ä» [50, 30, 30, 20]
# æ ·æœ¬æ•°: 3.9M â†’ 1.2M
```

### âœ… ä¿®å¤6: é™ä½ Batch Size (`src/config.py`)

```python
BATCH_SIZE = 256  # ä» 512 é™ä½ï¼Œæ›´ç¨³å®šçš„æ¢¯åº¦
```

### âœ… ä¿®å¤7: **Target å½’ä¸€åŒ–** (`src/train.py`) â­ **æœ€å…³é”®!**

```python
# è®­ç»ƒæ—¶
targets_normalized = self._normalize_targets(targets)  # å½’ä¸€åŒ–åˆ° [0, 1]
predictions, _ = self.model(features)  # æ¨¡å‹é¢„æµ‹ [0, 1]
loss = self.criterion(predictions, targets_normalized, weights)

# è®¡ç®—æŒ‡æ ‡æ—¶
predictions_bps = self._denormalize_targets(predictions)  # æ¢å¤åˆ° bps
mae = torch.abs(predictions_bps - targets_bps).mean()
```

**ä¸ºä»€ä¹ˆè¿™ä¸ªæœ€é‡è¦ï¼Ÿ**
- **ä¹‹å‰**: features åœ¨ [0,1], target åœ¨ [0, 1e7] â†’ æ•°å€¼ä¸åŒ¹é…
- **ä¹‹å**: features åœ¨ [0,1], target åœ¨ [0, 1] â†’ åŒä¸€å°ºåº¦
- **æ•ˆæœ**: Loss ä» 1e13 é™åˆ° 0.01-0.1

### âœ… ä¿®å¤8: ä¼˜åŒ–æ•°æ®åŠ è½½ (`src/dataset.py`)

```python
num_workers=4  # ä» 8 é™ä½
# ç§»é™¤ persistent_workers=True
```

---

## ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | å½±å“ |
|------|---------|------|
| `src/config.py` | å½’ä¸€åŒ–èŒƒå›´ã€å­¦ä¹ ç‡ã€æƒé‡ã€é‡é‡‡æ · | ç¨³å®šæ€§ â­â­â­ |
| `src/dataset.py` | Clippingã€num_workers | ç¨³å®šæ€§ + é€Ÿåº¦ â­â­ |
| `src/train.py` | Target å½’ä¸€åŒ–/åå½’ä¸€åŒ– | è®­ç»ƒæˆåŠŸå…³é”® â­â­â­â­â­ |

---

## é¢„æœŸæ”¹è¿›å¯¹æ¯”

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤å | æ”¹è¿› |
|------|--------|--------|------|
| **Loss** | NaN / 6.7e13 | 0.01-0.1 | âœ… æ­£å¸¸ |
| **GPU åˆ©ç”¨ç‡** | 7-10% | 60-80% | âœ… 8å€æå‡ |
| **è®­ç»ƒé€Ÿåº¦** | 49-52 it/s | 200-500 it/s | âœ… 5å€æå‡ |
| **æ ·æœ¬æ•°** | 3,929,244 | 1,235,579 | âœ… 3å€å‡å°‘ |
| **å†…å­˜ä½¿ç”¨** | 484MB | 400-600MB | âœ… ç¨³å®š |
| **è®­ç»ƒç¨³å®šæ€§** | âŒ å¤±è´¥ | âœ… æˆåŠŸ | âœ… å…³é”® |

---

## æŠ€æœ¯åŸç†è§£é‡Š

### ä¸ºä»€ä¹ˆ Target å½’ä¸€åŒ–è¿™ä¹ˆé‡è¦ï¼Ÿ

**ç¥ç»ç½‘ç»œçš„æ•°å€¼ç¨³å®šæ€§ä¾èµ–äºè¾“å…¥è¾“å‡ºåŒå°ºåº¦ï¼š**

1. **LSTM å•å…ƒ**:
   - å†…éƒ¨ä½¿ç”¨ sigmoid/tanh æ¿€æ´»å‡½æ•°
   - è¾“å‡ºèŒƒå›´: [-1, 1]
   - å¦‚æœ target = 10,000,000ï¼Œæ¢¯åº¦ä¼šçˆ†ç‚¸

2. **MSE Loss**:
   ```
   æœªå½’ä¸€åŒ–: (pred - target)Â²
            = (10 - 10,000,000)Â² 
            = 1e14 â† å·¨å¤§ï¼
   
   å½’ä¸€åŒ–:   (0.01 - 0.95)Â²
            = 0.88 â† åˆç†
   ```

3. **æ¢¯åº¦æµ**:
   ```
   æœªå½’ä¸€åŒ–: âˆ‚L/âˆ‚w = 2 Ã— (pred - target) Ã— âˆ‚pred/âˆ‚w
            = 2 Ã— 10,000,000 Ã— ... â† æ¢¯åº¦çˆ†ç‚¸
   
   å½’ä¸€åŒ–:   âˆ‚L/âˆ‚w = 2 Ã— 0.94 Ã— ... â† æ­£å¸¸
   ```

### ä¸ºä»€ä¹ˆå‡å°‘é‡é‡‡æ ·èƒ½æé€Ÿï¼Ÿ

**æ•°æ®åŠ è½½æ˜¯ç“¶é¢ˆï¼š**

```
é‡é‡‡æ ·å‰: 3.9M æ ·æœ¬ / 256 batch = 15,273 batches/epoch
         â†’ æ¯ä¸ª batch éœ€è¦ä»ç£ç›˜è¯»å–ã€å¤„ç†
         â†’ CPU æ»¡è½½ï¼ŒGPU ç©ºé—²

é‡é‡‡æ ·å: 1.2M æ ·æœ¬ / 256 batch = 4,827 batches/epoch
         â†’ 3å€å‡å°‘ I/O æ—¶é—´
         â†’ GPU æœ‰æ•°æ®å¯å¤„ç†
```

---

## å¦‚ä½•éªŒè¯ä¿®å¤æˆåŠŸï¼Ÿ

### âœ… æ£€æŸ¥æ¸…å•

1. **Loss æ˜¯æ­£å¸¸æ•°å€¼**
   ```
   âœ… Loss: 0.05-0.15 (ç¬¬1ä¸ªepoch)
   âŒ Loss: nan, inf, 1e13
   ```

2. **Loss ç¨³å®šä¸‹é™**
   ```
   Epoch 1: 0.12
   Epoch 2: 0.09
   Epoch 3: 0.07  âœ…
   ```

3. **GPU åˆ©ç”¨ç‡é«˜**
   ```
   âœ… GPU-Util: 60-80%
   âŒ GPU-Util: < 20%
   ```

4. **è®­ç»ƒé€Ÿåº¦å¿«**
   ```
   âœ… Speed: 200-500 it/s
   âŒ Speed: < 100 it/s
   ```

5. **æŒ‡æ ‡åˆç†**
   ```
   MAE: 100,000-500,000 bps (0.1-0.5 Mbps)  âœ…
   RÂ²: > 0.5 (ç¬¬10ä¸ªepoch)  âœ…
   ```

---

## å¼€å§‹è®­ç»ƒ

```bash
# 1. ç¡®ä¿åœæ­¢æ—§çš„è®­ç»ƒ
# åœ¨ terminal 2 æŒ‰ Ctrl+C

# 2. æ£€æŸ¥é…ç½®
cat src/config.py | grep -E "LEARNING_RATE|BATCH_SIZE|NORM_STATS" -A 2

# 3. å¼€å§‹æ–°è®­ç»ƒ
cd src
python3 train.py

# 4. ç›‘æ§ GPU (åœ¨å¦ä¸€ä¸ªç»ˆç«¯)
watch -n 0.5 nvidia-smi
```

---

## åç»­ä¼˜åŒ–å»ºè®®

å¦‚æœè®­ç»ƒæˆåŠŸï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **å¢å¤§ Batch Size**: 256 â†’ 512 (æ›´å¿«è®­ç»ƒ)
2. **æé«˜å­¦ä¹ ç‡**: 1e-4 â†’ 2e-4 (æ›´å¿«æ”¶æ•›)
3. **æ¢å¤éƒ¨åˆ†é‡é‡‡æ ·**: [10,5,5,5] â†’ [20,10,10,10]

**ä½†å…ˆç¡®ä¿å½“å‰é…ç½®ç¨³å®šï¼**

---

## é—®é¢˜æ’æŸ¥

å¦‚æœè¿˜æœ‰é—®é¢˜ï¼š

### Loss ä»ç„¶å¾ˆå¤§ (> 1)
```bash
# æ£€æŸ¥å½’ä¸€åŒ–æ˜¯å¦ç”Ÿæ•ˆ
python3 -c "from config import Config; print(Config.NORM_STATS)"
# åº”è¯¥çœ‹åˆ° max=10000, ä¸æ˜¯ 5000
```

### GPU åˆ©ç”¨ç‡ä»ç„¶ä½
```bash
# æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹å ç”¨ GPU
nvidia-smi
# æ£€æŸ¥ Python è¿›ç¨‹æ˜¯å¦å¡ä½
ps aux | grep python3
```

### é€Ÿåº¦ä»ç„¶æ…¢
```bash
# å°è¯•é™ä½ num_workers
# åœ¨ dataset.py ä¸­æ”¹ä¸º num_workers=2
```

---

## æ€»ç»“

è¿™æ¬¡ä¿®å¤çš„æ ¸å¿ƒæ˜¯**æ•°å€¼å°ºåº¦åŒ¹é…**ï¼š
- âœ… Features: [0, 1] (å½’ä¸€åŒ– + clipping)
- âœ… Targets: [0, 1] (å½’ä¸€åŒ–)
- âœ… Predictions: [0, 1] (æ¨¡å‹è¾“å‡º)
- âœ… Loss: 0.01-0.1 (æ­£å¸¸èŒƒå›´)

æ‰€æœ‰æ•°å€¼åœ¨åŒä¸€ä¸ªå°ºåº¦ä¸Šï¼Œæ¢¯åº¦æ‰èƒ½ç¨³å®šæµåŠ¨ï¼
